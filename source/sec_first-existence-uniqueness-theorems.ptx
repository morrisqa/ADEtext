<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-existencethms">
  <title>Existence &amp; Uniquess Theorem</title>
  <subsection xml:id="subsec-prelim">
    <title>Some Preliminaries</title>
    <p>
      Before we can discuss existence and uniqueness theorems for initial value problems, we must first spend some time discussing properties of functions and sets of functions.  Before we can proceed, however, it is important that we are clear about what a differential equation is and what we mean when we say that a function is a solution to a particular differential equation.
      <definition xml:id="def-de">
       <statement>
         <p>
           An ordinary differential equation of order <m>n</m> is an equation of the form
           <me>
             F(t,x(t),x'(t), \ldots, x^{(n)}(t))=0,
           </me>
           where <m>F:\mathbb{R}^{n+1} \to \mathbb{R}</m> is a function.  The differential equation is said to be in normal form if it can be written in the form
           <me>
             x^{(n)}(t)=f(t,x(t),x'(t), \ldots, x^{(n-1)}(t)).
           </me>
         </p>
       </statement>
     </definition>
    <p>
      Every differential equation of order <m>n</m> which is written in normal form can be converted into an <m>n</m>-dimensional system of first order differential equations, as we illustrate in the next example.
    </p>

    <example xml:id="ex1-1">
      <statement>
        <p>
          Rewrite the second-order differential equation
          <me>
            x''(t)  + x'(t) \cdot x(t) = 0
          </me>
          as a system of two first-order differential equations.

        </p>
      </statement>
      <solution>
        <p>
          Let <m>x_1(t)=x(t)</m> and <m>x_2(t)=x'(t)</m>.  Then <m>x_1'(t)=x'(t)=x_2(t)</m> and <m>x_2'(t)=x''(t)=-x'(t) \cdot x(t) = x_2(t)\cdot x_1(t)</m>.  Hence, we can rewrite the second-order differential equation as <me>
            \left\{ \begin{array}{l} x_1'(t)=x_2(t) \\ x_2'(t)=x_2(t)\cdot x_1(t) \end{array} \right.
          </me>

        </p>
      </solution>
    </example>

      In this section (and the next few sections), we will concern ourselves with initial value problems of the form

        <men xml:id="eq-picard">
          \left\{ \begin{array}{l} x^\prime = \vec{f}(t,x) \\ x(\alpha)=\beta \end{array} \right.
        </men>
        where <m>\alpha,\beta \in \mathbb{R}</m> and <m>f:D \to \mathbb{R}^n</m> is a continuous function defined on an open set <m> D=I \times \mathbb{R} \subset \mathbb{R}^2</m> containing <m>(\alpha,\beta)</m>.
    </p>
    <p>
      It is reasonable to ask why we restrict ourselves to only first order ordinary differential equations.  There are two reasons: the first is that every
    </p>
    <p>
      As <xref ref="ex2" /> showed, continuity of <m>\vec{f}</m> is not enough to guarantee the existence of a unique solution. It's worth recalling the problem here, which was,
      <me>
        \left\{ \begin{array}{l} y'=y^{\frac{2}{3}} \\ y(0)=0 \end{array} \right.
      </me>
      Clearly we need to seek out a more stringent criteria for <m>\vec{f}</m> if we want to ensure that the initial value problem has a unique solution.  Our natural intuition from calculus may suggest to us that we try to establish an existence and uniqueness theorem when <m>\vec{f}</m> is differentiable.  This is quite a reasonable hypothesis, particularly since we note that the failure of uniqueness occurs when the initial value <m>y(0)=0</m> occurs where the function <m>f(y)=y^\frac{2}{3}</m> fails to be differentiable.
    </p>
    <p>
      It is important to note here the way in which <m>f(y)</m> fails to be differentiable. In particular, <m>f(y)</m> is differentiable for all <m>y\neq 0</m> and <m>\displaystyle \lim_{y \to 0^+}f'(y)\lim_{y \to 0^+}f'(y)=\infty</m>.  What is unknown then is whether it is the simple failure of the derivative exist that is the issue, or whether it is the unboundedness of the derivative that is the issue.  It turns out that the issue is, in fact, the latter.  We can prove that an initial value problem has a unique solution if we assume continuity of <m>\vec{f}(t,\vec{x})</m> in both variables and boundedness of the partial derivative <m>\vec{f}_x(t,\vec{x})</m>.  But we can do better!
    </p>
    <p>
      As it turns out, the key necessary for existence and uniqueness is for <m>f(t,y)</m> to not change too rapidly as <m>y</m> varies.  There are many ways to quantify this (one being the boundedness of the partial derivative as discussed above), but we will use the notion of a Lipschitz condition, which we defined below.
    </p>
     <definition xml:id="def-lipschitz">
      <statement>
        <p>
          A function <m>\vec{f}:D\to\mathbb{R}^n</m> is said to satisfy a <em>Lipschitz condition with respect to <m>x</m> </em> on the open set <m>D \subset \mathbb{R} \times \mathbb{R}^n</m> if, for any rectangle
          <me>
            \Omega:=\{(t,\vec{x}) \mid |t-t_0|\le a, \; \|\vec{x}-\vec{x}_0\| \le b \} \subset D,
          </me>
          there exists a constant <m>K</m> (depending on <m>\Omega</m>) such that
          <me>
            \|\vec{f}(t,\vec{x})-\vec{f}(t,\vec{y})\|\le K\|\vec{x}-\vec{y}\|
          </me>
          for all <m>(t,\vec{x}),(t,\vec{y}) \in \Omega</m>.
        </p>
      </statement>
    </definition>

  </subsection>


  <theorem xml:id="thm-picard">
    <title>Picard's Existence &amp; Uniqueness Theorem</title>
    <statement>
        <p>
          If <m>\vec{f}</m> satisfies a Lipschitz condition  with respect to <m>x</m>, then <xref ref="eq-picard" /> has a unique solution in a neighborhood of <m>t=\alpha</m>.
        </p>
    </statement>
    <proof>
      <p>
        The proof of this theorem relies on the Contraction Mapping Theorem.
      </p>
    </proof>
  </theorem>
</section>
